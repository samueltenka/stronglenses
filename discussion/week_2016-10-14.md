	author: daniel zhang

	credits: jonathan stroud, sam tenka

	date: 2016-oct-14

	descr: Questions for Dr. Brian Nord for strong lens project


# 0. Action Items

@all: Meet `2016-oct-28` at `11:30 CST (12:30 EST)`

@nord: Where can we access to code for simulations?

@nord: Could we view the paper draft?

@nord: Introduce coauthor?

@pi224: Literature review & reach out to Stanford workers 

@sam: Train neural network for preliminary results. 

@pi224 and @sam: Integrate current system with simulator/classifier code. 

# 1. Questions & Update

## 1.0. Data

@nord: How realistic are the simulations? What assumptions
do they make about atmospheric distortion, about arrangement,
spectra, and shapes of sources? About distributions of masses?
Etc.

@nord: What symmetries and densities can we expect in our data?
Explicitly: how much scale, rotational, and translational invariance
should we expect? How sparsely distributed are lightsources in the
sky? What scales will we need to keep in mind (#pixels... #images...)
Could global context be important? 

@nord: Our simulation data contains centered crops of potential
strong lenses. How would this translate to the non-simulated case?
What are current methods for centering and cropping potential
strong lenses (automated... grad students...)? 

## 1.1. Related Work

@nord: Is there any prior or related work we should look into?
For instance, we found a paper on strong lens detection via neural 
nets (http://cs231n.stanford.edu/reports/cpd_final.pdf). How many
players? Differences and similarities in the space of projects
and approaches? How can we reach out to other workers?

## 1.2. Project Plan

@pi224 and @sam read 1 paper on classification architecture,
implemented some neural nets in Keras, and
prepared the data for neural net training. We have not yet
started training though.

@nord: Detection and classification are related but distinct problems.
Which is our ultimate goal? Which should we strive for in our initial stages?

@nord: What is the over-arching plan for this project? A major
stage will be building an accurate classifier. What is next?
How will we integrate it into existing workflows?

@nord: Validation methodology: what metrics should we optimize for?
Beyond what threshold will our work be useful? Publishable?

@nord: Could we meet once every two weeks?

# 2. Notes

## 2.0. Data

Data augmentation: later want to add contaminators such as stars,
edge-on galaxies etc. Augment by reflecting, rotating, scaling.
Also augment by translating-then-cropping (rather than cropping
then translating): generate 100x100 image and take random 64x64 subimage.

Scale of strong lenses: may assume fixed (to 0th order).

Global context: Our galaxy scale lenses need global context.
Versus cluster scale (not our current focus), which need global context.

How does detection reduce to classifiction?
Currently, community has automated proposal process
based not on images but on redshifts/blueshifts. 

## 2.1. Related Work

Reach out to other workers. Idea is: several loosely connected
groups, collaborative & working on different subtopics / papers
within the realm of automating the processing of astronomical surveys. 

## 2.2. Project Plan 

Longterm Dream: fully-automated detection of strong lenses within survey images.

For publication in astro community, need data-focused results:
need a model that is tunable to great precision or great recall.
Goal: introduce more deep learning to astro community.

Goal: Try to get best ROC curve / confusion matrix.

Timeline: Dark energy survey is ongoing with data released in batches.
New batch in ~1 month, so let us have a runnable system by December.
LSST data will come in ~years; longterm goal to extract, automatically,
lenses from that data.

Future work:
Estimate lens masses or even mass-vs-radius distributions from image data?
Could set up as regression problem; would need to revise simulation to
return (image, mass) pairs.

